{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing recommendations: Overall strategy\n",
    "\n",
    "In what follows, we will implement three collaborative filtering strategies which comes under \"user-based\" paradigm.\n",
    "In \"user-based\" paradigm, the focus is on the past behaviour of users (\"what did they watch?\", \"how much did they rate?\").\n",
    "\n",
    "### Steps involved:\n",
    "\n",
    "* Evaluate similarity between two users.\n",
    "* Find users similar to the user you want to recommend movies to.\n",
    "* Rank movies among the ones seen by similar users.\n",
    "* Recommend the best movies which the user has not seen.\n",
    "\n",
    "The three collaborative filtering strategies are:\n",
    "\n",
    "1. Movies that have been seen by most of the similar users.\n",
    "2. Movies that are watched AND liked by most of the similar users.\n",
    "3. Movies that are liked by users giving similar ratings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building graph database from DSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from py2neo import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neo4j_uname = 'neo4j'\n",
    "neo4j_pswd = 'Impelsys!#%&('\n",
    "\n",
    "# Connect to neo4j\n",
    "graph = Graph(host='localhost', http_port=7474, user=neo4j_uname, password=neo4j_pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading user data\n",
    "users_col = ['id', 'age', 'gender', 'occupation', 'zipcode']\n",
    "users = pd.read_csv('movie-dataset/u.user', sep='|', header=None, names=users_col)\n",
    "num_users = users.shape[0]\n",
    "\n",
    "# Loading genre data\n",
    "genres_col = ['name', 'id']\n",
    "genres = pd.read_csv('movie-dataset/u.genre', sep='|', header=None, names=genres_col)\n",
    "num_genres = genres.shape[0]\n",
    "\n",
    "# Loading movie data\n",
    "movie_col = ['id', 'title', 'release date', 'useless', 'IMDb url']\n",
    "movie_col = movie_col + genres['id'].tolist()\n",
    "movies = pd.read_csv('movie-dataset/u.item', sep='|', header=None, names=movie_col)\n",
    "movies = movies.fillna('unknown')\n",
    "num_movies = movies.shape[0]\n",
    "\n",
    "# Loading ratings data\n",
    "ratings_col = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('movie-dataset/u.data', sep='\\t', header=None, names=ratings_col)\n",
    "num_ratings = ratings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the nodes relative to Users, each one being identified by its user_id\n",
    "# Begin db transaction\n",
    "tx = graph.begin()\n",
    "\n",
    "statement = \"MERGE (a:User {user_id:{A}}) RETURN a\"\n",
    "\n",
    "for u in users['id']:\n",
    "    # Replace 'A' with user_id\n",
    "    tx.run(statement, {'A': u})\n",
    "\n",
    "# Commit db transaction\n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the nodes relative to Genres,\n",
    "# each one being identified by its genre_id and with the property name \n",
    "tx = graph.begin()\n",
    "statement = \"MERGE (a:Genre {genre_id:{A}, name:{B}}) RETURN a\"\n",
    "\n",
    "for g, row in genres.iterrows():\n",
    "    # Replace 'A' and 'B' with genre_id and name respectively\n",
    "    tx.run(statement, {'A': row.iloc[1], 'B': row.iloc[0]})\n",
    "    \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Movie nodes with properties movie_id, title and url ; then create the Is_genre edges\n",
    "tx = graph.begin()\n",
    "movie_stmt = 'MERGE (a:Movie {movie_id:{A}, title:{B}, url:{C}}) RETURN a'\n",
    "genre_stmt = '''MATCH (g:Genre {genre_id:{D}})\n",
    "                MATCH (m:Movie {movie_id:{A}})\n",
    "                MERGE (m)-[r:Is_genre]->(g) RETURN r'''\n",
    "\n",
    "# Looping over movies\n",
    "for m, row in movies.iterrows():\n",
    "    movie_id = row.loc['id']\n",
    "    movie_title = row.loc['title'].decode('latin-1')\n",
    "    movie_url = row.loc['IMDb url']\n",
    "    \n",
    "    # Create Movie nodes\n",
    "    tx.run(movie_stmt, {'A': movie_id, 'B': movie_title, 'C': movie_url})\n",
    "    \n",
    "    # Create an array of booleans for genre (sliced from each movie data)\n",
    "    is_genre = row.iloc[-19:] == 1\n",
    "    # Form an array of genre_ids\n",
    "    related_genres = genres[is_genre].axes[0].values\n",
    "    \n",
    "    # Looping over related genres\n",
    "    for genre in related_genres:\n",
    "        # Create Movie-Genre relationships\n",
    "        tx.run(genre_stmt, {'A': movie_id, 'D': genre})\n",
    "    \n",
    "    # For every 100 movies, push queued statements to the server for execution to avoid one massive \"commit\"\n",
    "    if m % 100 == 0:\n",
    "        tx.process()\n",
    "        \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the Has_rated edges, with rating as property\n",
    "tx = graph.begin()\n",
    "statement = '''MATCH (u:User {user_id:{A}})\n",
    "               MATCH (m:Movie {movie_id:{B}})\n",
    "               MERGE (u)-[r:Has_rated {rating:{C}}]->(m) RETURN r'''\n",
    "\n",
    "# Looping over ratings\n",
    "for r, row in ratings.iterrows():\n",
    "    user_id = row.loc['user_id']\n",
    "    movie_id = row.loc['item_id']\n",
    "    rating = row.loc['rating']\n",
    "    \n",
    "    # Create User-Movie relationship (i.e. Ratings)\n",
    "    tx.run(statement, {'A': user_id, 'B': movie_id, 'C': rating})\n",
    "    \n",
    "    if r % 100 == 0:\n",
    "        tx.process()\n",
    "        \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create index\n",
    "graph.run('CREATE INDEX ON :User(user_id)')\n",
    "graph.run('CREATE INDEX ON :Movie(movie_id)')\n",
    "graph.run('CREATE INDEX ON :Genre(genre_id)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add new user and the ratings from the user\n",
    "num_users += 1\n",
    "new_user_id = num_users\n",
    "\n",
    "# Create a node for new user\n",
    "tx = graph.begin()\n",
    "statement = 'MERGE (u:User {user_id:{A}}) RETURN u'\n",
    "tx.run(statement, {'A': new_user_id})\n",
    "tx.commit()\n",
    "\n",
    "# Load ratings from new user\n",
    "new_user_ratings = pd.read_csv('movie-dataset/new_user.data', sep='|', header=None, names=['item_id', 'rating'])\n",
    "num_ratings += new_user_ratings.shape[0]\n",
    "\n",
    "# Create Has_rated relations between new user and movies\n",
    "tx = graph.begin()\n",
    "statement = '''MATCH (u:User {user_id:{A}})\n",
    "               MATCH (m:Movie {movie_id:{B}})\n",
    "               MERGE (u)-[r:Has_rated {rating:{C}}]->(m) RETURN r'''\n",
    "\n",
    "# Looping over new user ratings\n",
    "for r, row in new_user_ratings.iterrows():\n",
    "    rating = row.loc['rating']\n",
    "    movie_id = row.loc['item_id']\n",
    "    tx.run(statement, {'A': new_user_id, 'B': movie_id, 'C': rating})\n",
    "    \n",
    "    if r % 100 == 0:\n",
    "        tx.process()\n",
    "        \n",
    "tx.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 1:\n",
    "\n",
    "* Compute similarity between two users u<sub>1</sub> and u<sub>i</sub> as the ratio of number of movies they have in common.\n",
    "\n",
    "   ***similarity = number of movies seen by both u<sub>1</sub> and u<sub>i</sub> / number of movies seen by u<sub>1</sub>***\n",
    "\n",
    "\n",
    "* Find the set of users similar to u<sub>1</sub>. We can define a threshold, so that we can reduce the number of users and optimize the selectivity of the subset.\n",
    "\n",
    "\n",
    "* Find the set of movies rated by similar users, which is not seen by u<sub>1</sub>.\n",
    "\n",
    "\n",
    "* Rank each movie, by computing the proportion of similar users who have seen that particular movie.\n",
    "\n",
    "   ***rank = number of similar users who have seen that particular movie / total number of similar users***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = 944\n",
    "threshold = 0.5\n",
    "\n",
    "query = (\n",
    "    # Count movies rated by user1 as countm\n",
    "    'MATCH (u1:User {user_id: {user_id}})-[:Has_rated]->(m1:Movie) '\n",
    "    'WITH count(m1) as countm '\n",
    "    # Find users who share atleast 1 movie with u1\n",
    "    'MATCH (u1:User {user_id: {user_id}})-[:Has_rated]->(m1:Movie) '\n",
    "    'MATCH (m1)<-[r:Has_rated]-(u2:User) WHERE NOT u2=u1 '\n",
    "    # Compute similarity between users\n",
    "    'WITH u2, countm, tofloat(count(r))/countm as sim WHERE sim>{threshold} '\n",
    "    # Count number of similar users as countu\n",
    "    'WITH count(u2) as countu, countm '\n",
    "    'MATCH (u1:User {user_id: {user_id}})-[:Has_rated]->(m1:Movie) '\n",
    "    'MATCH (m1)<-[r:Has_rated]-(u2:User) WHERE NOT u2=u1 '\n",
    "    # Compute similarity\n",
    "    'WITH u1, u2, countu, tofloat(count(r))/countm as sim WHERE sim>{threshold} '\n",
    "    # Find movies that were rated by at least one similar user, but not by u1\n",
    "    'MATCH (m:Movie)<-[r:Has_rated]-(u2) '\n",
    "    'WHERE NOT (m)<-[:Has_rated]-(u1) '\n",
    "    'RETURN DISTINCT m as movie, tofloat(count(r))/countu as score ORDER BY score DESC '\n",
    "    'LIMIT 10')\n",
    "\n",
    "tx = graph.begin()\n",
    "recommended_movies = tx.run(query, {'user_id': user_id, 'threshold': threshold})\n",
    "\n",
    "result = tx.commit()\n",
    "for num, movie in enumerate(recommended_movies.data()):\n",
    "    print str(num + 1).zfill(2) + '.', movie['movie']['title'].ljust(70, '-'), movie['score']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
